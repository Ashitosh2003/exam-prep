Implement a simple map-reduce job that builds an inverted index on the set of input documents(Hadoop):



Pre requirements:
	Install Git and Hadoop.

	Step 1: git clone https://github.com/big-data-europe/docker-hadoop
        	cd docker-hadoop/
	Step 2: docker-compose up -d
	Step 3: docker container ls
	Step 4: docker exec -it namenode /bin/bash

C:\Users\gadea>cd docker-hadoop

C:\Users\gadea\docker-hadoop>docker exec -it namenode bash

root@053dec888e1f:/# hdfs dfs -ls /
Found 1 items
drwxr-xr-x   - root supergroup          0 2025-03-31 17:13 /rmstate

root@053dec888e1f:/# exit


What's next?
  Try Docker Debug for seamless, persistent debugging tools in any container or image â†’ docker debug namenode
  Learn more at https://docs.docker.com/go/debug-cli/

C:\Users\gadea\docker-hadoop>docker cp "C:\Users\gadea\OneDrive\Desktop\InvertedIndex.java" namenode:/home/
Successfully copied 4.1kB to namenode:/home/

C:\Users\gadea\docker-hadoop>
C:\Users\gadea\docker-hadoop>docker exec -it namenode bash

root@053dec888e1f:/# echo "hadoop is a bad">doc1.txt
root@053dec888e1f:/# echo "hadoop is a waste">doc2.txt
root@053dec888e1f:/# echo "hadoop is a even more worst">doc3.txt


root@053dec888e1f:/# hdfs dfs -mkdir /bda

root@053dec888e1f:/# hdfs dfs -put doc*.txt /bda/

2025-04-02 07:31:36,890 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:31:37,002 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:31:37,449 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
root@053dec888e1f:/# hdfs dfs -ls /bda/
Found 3 items
-rw-r--r--   3 root supergroup         16 2025-04-02 07:31 /bda/doc1.txt
-rw-r--r--   3 root supergroup         18 2025-04-02 07:31 /bda/doc2.txt
-rw-r--r--   3 root supergroup         28 2025-04-02 07:31 /bda/doc3.txt

root@053dec888e1f:/# cd /home/


root@053dec888e1f:/home# javac -classpath $(hadoop classpath) -d . InvertedIndex.java

root@053dec888e1f:/home# jar cf invertedindex.jar InvertedIndex*.class

root@053dec888e1f:/home# hadoop jar invertedindex.jar InvertedIndex /bda /bda/output

2025-04-02 07:34:53,013 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.2:8032
2025-04-02 07:34:53,156 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200
2025-04-02 07:34:53,284 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2025-04-02 07:34:53,304 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1743578647017_0001
2025-04-02 07:34:53,374 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:34:53,469 INFO input.FileInputFormat: Total input files to process : 3
2025-04-02 07:34:53,502 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:34:53,943 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:34:54,366 INFO mapreduce.JobSubmitter: number of splits:3
2025-04-02 07:34:54,518 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2025-04-02 07:34:54,557 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1743578647017_0001
2025-04-02 07:34:54,557 INFO mapreduce.JobSubmitter: Executing with tokens: []
2025-04-02 07:34:54,678 INFO conf.Configuration: resource-types.xml not found
2025-04-02 07:34:54,679 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-04-02 07:34:55,079 INFO impl.YarnClientImpl: Submitted application application_1743578647017_0001
2025-04-02 07:34:55,130 INFO mapreduce.Job: The url to track the job: http://resourcemanager:8088/proxy/application_1743578647017_0001/
2025-04-02 07:34:55,131 INFO mapreduce.Job: Running job: job_1743578647017_0001
2025-04-02 07:35:00,199 INFO mapreduce.Job: Job job_1743578647017_0001 running in uber mode : false
2025-04-02 07:35:00,200 INFO mapreduce.Job:  map 0% reduce 0%
2025-04-02 07:35:05,256 INFO mapreduce.Job:  map 33% reduce 0%
2025-04-02 07:35:06,262 INFO mapreduce.Job:  map 67% reduce 0%
2025-04-02 07:35:07,267 INFO mapreduce.Job:  map 100% reduce 0%
2025-04-02 07:35:10,288 INFO mapreduce.Job:  map 100% reduce 100%
2025-04-02 07:35:11,302 INFO mapreduce.Job: Job job_1743578647017_0001 completed successfully
2025-04-02 07:35:11,364 INFO mapreduce.Job: Counters: 55
        File System Counters
                FILE: Number of bytes read=111
                FILE: Number of bytes written=915651
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=356
                HDFS: Number of bytes written=170
                HDFS: Number of read operations=14
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Killed map tasks=1
                Launched map tasks=3
                Launched reduce tasks=1
                Rack-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=20284
                Total time spent by all reduces in occupied slots (ms)=24016
                Total time spent by all map tasks (ms)=5071
                Total time spent by all reduce tasks (ms)=3002
                Total vcore-milliseconds taken by all map tasks=5071
                Total vcore-milliseconds taken by all reduce tasks=3002
                Total megabyte-milliseconds taken by all map tasks=20770816
                Total megabyte-milliseconds taken by all reduce tasks=24592384
        Map-Reduce Framework
                Map input records=3
                Map output records=14
                Map output bytes=188
                Map output materialized bytes=175
                Input split bytes=294
                Combine input records=0
                Combine output records=0
                Reduce input groups=8
                Reduce shuffle bytes=175
                Reduce input records=14
                Reduce output records=8
                Spilled Records=28
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=231
                CPU time spent (ms)=1290
                Physical memory (bytes) snapshot=1126907904
                Virtual memory (bytes) snapshot=23803637760
                Total committed heap usage (bytes)=1027080192
                Peak Map Physical memory (bytes)=309338112
                Peak Map Virtual memory (bytes)=5115404288
                Peak Reduce Physical memory (bytes)=220360704
                Peak Reduce Virtual memory (bytes)=8461189120
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=62
        File Output Format Counters
                Bytes Written=170

root@053dec888e1f:/home# hdfs dfs -cat /bda/output/part-r-00000

2025-04-02 07:35:42,717 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
a       doc1.txt, doc2.txt, doc3.txt
bad     doc1.txt
even    doc3.txt
hadoop  doc3.txt, doc1.txt, doc2.txt
is      doc2.txt, doc3.txt, doc1.txt
more    doc3.txt
waste   doc2.txt
worst   doc3.txt
root@053dec888e1f:/home#


